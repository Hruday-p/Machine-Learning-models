# -*- coding: utf-8 -*-
"""employeesalaryprediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/Hruday-p/hruday/blob/main/employeesalaryprediction.ipynb
"""

import pandas as pd
data = pd.read_csv("/content/adult 3.csv")
data

data.shape #num of columns and rows

data.head(5) #first 5 values

data.tail(5) #last 5 values

data.isna() #null values

data.isna().sum()

print(data.occupation.value_counts())

print(data.gender.value_counts())

print(data['marital-status'].value_counts())

print(data['workclass'].value_counts())

print(data['education'].value_counts())

print(data['relationship'].value_counts())

print(data['race'].value_counts())

print(data['capital-gain'].value_counts())

print(data['capital-loss'].value_counts())

data.occupation.replace({'?':'Not Listed'},inplace=True)

print(data.occupation.value_counts())

data.workclass.replace({'?':'others'},inplace=True)

print(data['workclass'].value_counts())

data=data[data['workclass']!='Without-pay']
data=data[data['workclass']!='Never-worked']

print(data['workclass'].value_counts())

data.shape

data

data=data[data['education']!='5th-6th']
data=data[data['education']!='1st-4th']
data=data[data['education']!='Preschool']

print(data.education.value_counts())

data.shape

#redundancy[education, Educational-num]
data.drop('education', axis=1, inplace=True)
#deleted

data

#outlier
import matplotlib.pyplot as plt
plt.boxplot(data['age'])
plt.show()

data= data[(data['age']<=75)&(data['age']>=17)]

plt.boxplot(data['age'])
plt.show()

plt.boxplot(data['capital-gain'])
plt.show()

plt.boxplot(data['capital-loss'])
plt.show()

plt.boxplot(data['educational-num'])
plt.show()

data=data[(data['educational-num']<=16)&(data['educational-num']>=5)]

plt.boxplot(data['educational-num'])
plt.show()

plt.boxplot(data['hours-per-week'])
plt.show()

#label encoding
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
data['workclass']=le.fit_transform(data['workclass'])
data['marital-status']=le.fit_transform(data['marital-status'])
data['occupation']=le.fit_transform(data['occupation'])
data['relationship']=le.fit_transform(data['relationship'])
data['gender']=le.fit_transform(data['gender'])
data['race']=le.fit_transform(data['race'])
data['native-country']=le.fit_transform(data['native-country'])
data

x=data.drop(columns=['income']) #input
y=data['income'] #output

from sklearn.preprocessing import MinMaxScaler, LabelEncoder

# Label encode the 'relationship' column
le = LabelEncoder()
x['relationship'] = le.fit_transform(x['relationship'])

scaler = MinMaxScaler()
x = scaler.fit_transform(x)
x

import joblib

encoders = {}
for col in ['workclass', 'marital-status', 'occupation', 'relationship', 'race', 'gender', 'native-country']:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    encoders[col] = le

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=23, stratify=y)

x_train

#machine learning algorithm
from sklearn.neighbors import KNeighborsClassifier
knn=KNeighborsClassifier()
knn.fit(x_train,y_train)
predict=knn.predict(x_test)
predict

from sklearn.metrics import accuracy_score
accuracy_score(y_test,predict)

from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(x_train,y_train)
predict1=lr.predict(x_test)
predict1

from sklearn.metrics import accuracy_score
accuracy_score(y_test,predict1)

from sklearn.neural_network import MLPClassifier
mlp=MLPClassifier(solver='adam', hidden_layer_sizes=(5,2), random_state=23, max_iter=2000)
mlp.fit(x_train,y_train)
predict2=mlp.predict(x_test)
predict2

from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, OneHotEncoder

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

models = {
    "LogisticRegression": LogisticRegression(),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

for name, model in models.items():
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('model', model)
    ])

    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
plt.bar(results.keys(), results.values(), color='skyblue')
plt.ylabel('Accuracy Score')
plt.title('Model Comparison')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Define models
models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

# Train and evaluate
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    results[name] = acc
    print(f"{name}: {acc:.4f}")

# Get best model
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]
print(f"\n✅ Best model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Save the best model
joblib.dump(best_model, "best_model.pkl")
print("✅ Saved best model as best_model.pkl")
joblib.dump(encoders, "encoders.pkl")